{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "f = open(\"day_4_input.txt\")\n",
    "#Separate entries by two newlines, and then separate fields by space.\n",
    "input_list = f.read().split(\"\\n\\n\")\n",
    "input_list = [item.replace(\"\\n\", \" \").split(\" \") for item in input_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up input list as a dataframe\n",
    "df = pd.DataFrame(input_list)\n",
    "#Stack to associate them with their appropriate IDs, then re-index to remove the useless second row denoting field number\n",
    "df = df.stack().reset_index()[[\"level_0\", 0]].set_index(\"level_0\")\n",
    "#Split the remaining column by the colon, and expand.\n",
    "df = df[0].str.split(\":\", expand=True)\n",
    "\n",
    "#Re-index again with the new \"0\" column, which is the field name. Then unstack to make the fields the new columns and the respective values filled in\n",
    "df = df.reset_index().set_index(['level_0', 0]).unstack(-1)\n",
    "\n",
    "#For ease of reference just re-set columns\n",
    "df.columns = df.columns.unique(level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_4_part_1():\n",
    "    #duplicate the dataframe so we don't have to iterate on it\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    #create a new column named \"num_valid\" which is just how many non-NaN values are found\n",
    "    df_copy['num_valid'] = df_copy.count(axis=1)\n",
    "\n",
    "    #Create two masks, one for passports with 8 valid values and another for 7 with 'cid' missing\n",
    "    mask1 = df_copy['num_valid'] == 8\n",
    "    mask2 = (df_copy['num_valid'] == 7) & (df_copy['cid'].isna())\n",
    "\n",
    "    return len(df_copy.loc[mask1 | mask2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "235"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "day_4_part_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_4_part_2():\n",
    "    #duplicate the dataframe so we don't have to iterate on it\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    constraints = {\n",
    "        \"byr\": {\n",
    "            \"max\": 2002,\n",
    "            \"min\": 1920\n",
    "        },\n",
    "        \"iyr\": {\n",
    "            \"max\": 2020,\n",
    "            \"min\": 2010\n",
    "        },\n",
    "        \"eyr\": {\n",
    "            \"max\": 2030,\n",
    "            \"min\": 2020\n",
    "        },\n",
    "        \"hgt\": {\n",
    "            \"max\": {\n",
    "                \"cm\": 193,\n",
    "                \"in\": 76\n",
    "            },\n",
    "            \"min\": {\n",
    "                \"cm\": 150,\n",
    "                \"in\": 59\n",
    "            }\n",
    "        },\n",
    "        \"hcl\": r\"(^#[0-9a-f]{6}$)\",\n",
    "        \"ecl\": [\"amb\", \"blu\", \"brn\", \"gry\", \"grn\", \"hzl\", \"oth\"],\n",
    "        \"pid\": r\"(^[0-9]{9}$)\"\n",
    "    }\n",
    "    #Start creating masks based on the contraints\n",
    "\n",
    "    #Validate years\n",
    "    df_copy[['byr', 'iyr', 'eyr']] = df_copy[['byr', 'iyr', 'eyr']].astype(float)\n",
    "    byr_mask = (df_copy['byr'] >= constraints['byr']['min']) & (df_copy['byr'] <= constraints['byr']['max'])\n",
    "    iyr_mask = (df_copy['iyr'] >= constraints['iyr']['min']) & (df_copy['iyr'] <= constraints['iyr']['max'])\n",
    "    eyr_mask = (df_copy['eyr'] >= constraints['eyr']['min']) & (df_copy['eyr'] <= constraints['eyr']['max'])\n",
    "\n",
    "    #Height\n",
    "    df_copy['units'] = df_copy['hgt'].str[-2:]\n",
    "    df_copy['hgt'] =   df_copy['hgt'].str[:-2]\n",
    "    #Temporary mask to delete invalid units\n",
    "    temp_mask = ~df_copy['units'].isin(['cm', 'in'])\n",
    "    \n",
    "    #null out invalid units\n",
    "    df_copy.loc[temp_mask, 'units'] = np.nan\n",
    "    df_copy.loc[temp_mask, 'hgt'] =   np.nan\n",
    "    df_copy['hgt'] = df_copy['hgt'].astype(float)\n",
    "    cm_mask = ((df_copy['hgt'] >= constraints['hgt']['min']['cm']) & (df_copy['hgt'] <= constraints['hgt']['max']['cm'])) & (df_copy['units'] == 'cm')\n",
    "    in_mask = ((df_copy['hgt'] >= constraints['hgt']['min']['in']) & (df_copy['hgt'] <= constraints['hgt']['max']['in'])) & (df_copy['units'] == 'in')\n",
    "    hgt_mask = cm_mask | in_mask\n",
    "\n",
    "    #Hair color\n",
    "    hcl_mask = ~df_copy['hcl'].str.extract(constraints['hcl']).isna()[0]\n",
    "\n",
    "    #Eye color\n",
    "    ecl_mask = df_copy['ecl'].isin(constraints['ecl'])\n",
    "\n",
    "    #PID\n",
    "    pid_mask = ~df_copy['pid'].str.extract(constraints['pid']).isna()[0]\n",
    "\n",
    "    #join all the masks together and return the length\n",
    "    mask = byr_mask & iyr_mask & eyr_mask & hgt_mask & hcl_mask & ecl_mask & pid_mask\n",
    "    return len(df_copy[mask])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "day_4_part_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}